{"cells":[{"cell_type":"markdown","source":["# Evaluation of Poker hand\n  - Project by Akshay Bhatkar"],"metadata":{}},{"cell_type":"markdown","source":["## Objective\n  * Prediction of whether the Poker hand is good (recommended to play), bad (recommended to fold) or fair (may try)."],"metadata":{}},{"cell_type":"markdown","source":["## Attribute Information:\n\n* 1) S1 \"Suit of card #1\" \n  * Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs} \n\n* 2) C1 \"Rank of card #1\" \n  * Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King) \n\n* 3) S2 \"Suit of card #2\" \n  * Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs} \n\n* 4) C2 \"Rank of card #2\" \n  * Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King) \n\n* 5) S3 \"Suit of card #3\" \n  * Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs} \n\n* 6) C3 \"Rank of card #3\" \n  * Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King) \n\n* 7) S4 \"Suit of card #4\" \n  * Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs} \n\n* 8) C4 \"Rank of card #4\" \n  * Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King) \n\n* 9) S5 \"Suit of card #5\" \n  * Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs} \n\n* 10) C5 \"Rank of card 5\" \n  * Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King) \n\n* 11) CLASS \"Poker Hand\" \n  * Ordinal (0-9) \n\n* Class : Poker Hand\n  * 0: Nothing in hand; not a recognized poker hand \n  * 1: One pair; one pair of equal ranks within five cards \n  * 2: Two pairs; two pairs of equal ranks within five cards \n  * 3: Three of a kind; three equal ranks within five cards \n  * 4: Straight; five cards, sequentially ranked with no gaps \n  * 5: Flush; five cards with the same suit \n  * 6: Full house; pair + different rank three of a kind \n  * 7: Four of a kind; four equal ranks within five cards \n  * 8: Straight flush; straight + flush \n  * 9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush"],"metadata":{}},{"cell_type":"markdown","source":["## Download the data"],"metadata":{}},{"cell_type":"code","source":["%sh\nmkdir -p kaggle_project\ncurl 'http://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-testing.data' > kaggle_project/poker_hand.data\nls kaggle_project"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#read the poker_hand.data file as CSV\n# we keep header option as false since the file does not have any headers and we want default names\ndf_data = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'false')\\\n  .option('inferSchema', 'true')\\\n  .load(\"file:/databricks/driver/kaggle_project/poker_hand.data\")\ndf_data.show(3)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["df_data.printSchema()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["## Rename the columns"],"metadata":{}},{"cell_type":"code","source":["df = df_data.selectExpr('_c0 as card1suit','_c1 as card1rank', '_c2 as card2suit', '_c3 as card2rank', '_c4 as card3suit', '_c5 as card3rank', '_c6 as card4suit', '_c7 as card4rank', '_c8 as card5suit','_c9 as card5rank', '_c10 as class_poker_hand')"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["## Check the presence of Dirty Data:\n  * Check if suit value is less than 1 or greater than 4\n  * Check if rank value is less than 1 or greater than 13\n  * Check if class of poker hand has value less than 0 or greater than 9"],"metadata":{}},{"cell_type":"code","source":["df_dirtyRank = df[(df.card1rank < 1) | (df.card1rank > 13) | (df.card2rank < 1) | (df.card2rank > 13) | (df.card3rank < 1) | (df.card3rank > 13) | (df.card4rank < 1) | (df.card4rank > 13) | (df.card5rank < 1) | (df.card5rank > 13)]\n\ndf_dirtyRank.collect()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["df_dirtySuit = df[(df.card1suit > 4) | (df.card1suit < 1) | (df.card2suit < 1)| (df.card2suit > 4)| (df.card3suit < 1)| (df.card3suit > 4)| (df.card4suit < 1)| (df.card4suit > 4) | (df.card5suit < 1)| (df.card5suit > 4)]\ndf_dirtySuit.collect()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["df_dirtyClass = df[(df.class_poker_hand < 0) | (df.class_poker_hand > 13)]\ndf_dirtyClass.collect()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["## Data Cleaning\n* From the above results, we conclude that we do not have any dirty data.\n* We drop all null values if any with the below command."],"metadata":{}},{"cell_type":"code","source":["df_cleaned = df.dropna()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["## Data explored and explained"],"metadata":{}},{"cell_type":"code","source":["df_cleaned.show(3)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["df_cleaned.printSchema()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["df_cleaned.select('class_poker_hand').distinct().orderBy('class_poker_hand').show()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["#Check the count of each value for the class of poker hand\ndf_count = df_cleaned.select('class_poker_hand').orderBy('class_poker_hand').groupBy('class_poker_hand').count()\n\ndisplay(df_count)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["## Data transformation\n\n  * We add a new column \"grade\" to the DataFrame. It can have the following values:\n    * bad -> Not a recognized poker hand -> recommended to fold\n    * fair -> One pair -> Can try your luck and play\n    * good -> All hands better than 1 pair -> Recommeded to play since chances of winning are high"],"metadata":{}},{"cell_type":"code","source":["lookup = sqlContext.createDataFrame([(0,'Bad'),(1,'Fair'),(2,'Good'),(3,'Good'),(4,'Good'),(5,'Good'),(6,'Good'),(7,'Good'), (8,'Good'), (9, 'Good')], ('k','v'))\n\ndf_2 = (df_cleaned.join(lookup, df_cleaned[\"class_poker_hand\"] == lookup[\"k\"], \"leftouter\")\n    .drop(\"k\")\n    .withColumnRenamed(\"v\", \"grade\"))\ndf_2.show(3)\n# df_2.show()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["display(df_2.select('grade').groupBy('grade').count())"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["## Data Modeling"],"metadata":{}},{"cell_type":"code","source":["#Split the data into 80% train data and 20% test data\nsplitted_data = df_2.randomSplit([0.8, 0.2], 24)\ntrain_data = splitted_data[0]\ntest_data = splitted_data[1]\n\nprint \"Number of training records: \" + str(train_data.count())\nprint \"Number of testing records : \" + str(test_data.count())"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml import Pipeline, Model"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["stringIndexer_label = StringIndexer(inputCol=\"grade\", outputCol=\"label\").fit(df_2)\n# Note the above outputCol is label (the predicted column). Here we predict the class of the poker hand from the attributes below.\nstringIndexer_c1s = StringIndexer(inputCol=\"card1suit\", outputCol=\"card1suit_IX\")\nstringIndexer_c2s = StringIndexer(inputCol=\"card2suit\", outputCol=\"card2suit_IX\")\nstringIndexer_c3s = StringIndexer(inputCol=\"card3suit\", outputCol=\"card3suit_IX\")\nstringIndexer_c4s = StringIndexer(inputCol=\"card4suit\", outputCol=\"card4suit_IX\")\nstringIndexer_c5s = StringIndexer(inputCol=\"card5suit\", outputCol=\"card5suit_IX\")\n\nstringIndexer_c1r = StringIndexer(inputCol=\"card1rank\", outputCol=\"card1rank_IX\")\nstringIndexer_c2r = StringIndexer(inputCol=\"card2rank\", outputCol=\"card2rank_IX\")\nstringIndexer_c3r = StringIndexer(inputCol=\"card3rank\", outputCol=\"card3rank_IX\")\nstringIndexer_c4r = StringIndexer(inputCol=\"card4rank\", outputCol=\"card4rank_IX\")\nstringIndexer_c5r = StringIndexer(inputCol=\"card5rank\", outputCol=\"card5rank_IX\")\n"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["# Select the input columns for the model (and put them into one features column)\nvectorAssembler_features = VectorAssembler(inputCols=[\"card1suit_IX\", \"card2suit_IX\", \"card3suit_IX\", \"card4suit_IX\", \"card5suit_IX\", \"card1rank_IX\", \"card2rank_IX\", \"card3rank_IX\", \"card4rank_IX\", \"card5rank_IX\"], outputCol=\"features\")"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# The model - RandomForest\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["# Columns for the output\n# Convert from indexed labels (added above) back to original labels.\n# https://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.feature.IndexToString\nlabelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=stringIndexer_label.labels)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["# The ML pipeline\npipeline_rf = Pipeline(stages=[stringIndexer_label, stringIndexer_c1s, stringIndexer_c2s, stringIndexer_c3s, stringIndexer_c4s, stringIndexer_c5s, stringIndexer_c1r, stringIndexer_c2r, stringIndexer_c3r, stringIndexer_c4r, stringIndexer_c5r, vectorAssembler_features, rf, labelConverter])"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# Model training\nmodel_rf = pipeline_rf.fit(train_data)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["## Model Evaluation"],"metadata":{}},{"cell_type":"code","source":["# Model quality\npredictions = model_rf.transform(test_data)\nevaluatorRF = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluatorRF.evaluate(predictions)\nprint(\"Accuracy = %g\" % accuracy)\nprint(\"Test Error = %g\" % (1.0 - accuracy))"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["display(predictions)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["#Showing only 2 of the 3 predictions\npredictions.select('prediction').distinct().show()"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["correct = predictions.where(\"(label = prediction)\").count()\nincorrect = predictions.where(\"(label != prediction)\").count()\n\nresultDF = sqlContext.createDataFrame([['correct', correct], ['incorrect', incorrect]], ['metric', 'value'])\ndisplay(resultDF)"],"metadata":{},"outputs":[],"execution_count":37}],"metadata":{"name":"Poker_Hand","notebookId":3568699688752186},"nbformat":4,"nbformat_minor":0}
